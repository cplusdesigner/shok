The evaluator was written with two conflicting ideas.  One is that we
want to do as much "static analysis" (type checking, sanity code
checking) as possible before doing any "evaluation" (code execution).
This is important.

The conflicting idea is the stupid way in which we build our Node
tree.  The evaluator receives an AST input, breaks it into Tokens,
turn those tokens into Nodes, and builds a Tree of nodes on-line as it
gets them.  This process is ugly:
 - keep a "current position" iterator
 - get a token, make a new Node for it
 - if it's a normal node: add it as a child of the current position
 - if it's an open brace of some sort: descend into it
 - if it's a closing brace: ascend, mark as "complete" all the
   children, and perform static analysis checking.
  -- furthermore: if we were a "parenthesis" then these are removed
entirely, thus moving a subtree up a level.

These goals conflict because, for a code block ('{'), we should be
able to do some amount of "static analysis" the moment we complete a
statement (if not sooner; but we only get Statement-chunks from the
parser currently).  Waiting for the closing brace around a block is
too late.

This is a big enough change; it breaks our simple "setup, analyze,
evaluate" model.

I think the code model of Node-tree-creation is wrong.  It should be
more aware of what it's doing.  And we need a better model for our
code structures.  A block should contain a list of statements.  We
have certain kinds of statements, they should receive the "children"
parts that they need and process them as soon as they can/want.

-----

Block has a Global*, but it shouldn't.  Not every block needs one.
Global should just be a Scope
Scope is (has) a variables container, which is a map from names to
Object*s that it creates and owns.

The RootNode should be a Scope!!  That way
every regular Block can just defer to its parent scope the usual way,
and the root scope will never disappear.  Huzzah!

We'll still need Node to pass down a parentScope to *everybody*; every
kind of node probably wants this.  The RootNode is the only one with a
parentScope of NULL.

ok: have a getScope() which both RootNode and Block override to return
their scope. ??

Everybody has a parentScope.  A scope may have a parentScope too??

what are our actual requirements:
 - Node analyzeDown can set properties
 - every Node wants to be able to retrieve its local scope, add/del
   variables from it etc.
 - a RootNode needs to have/be this
 - a Block needs to have/be this (really? no, just marks where we need
   a scope down the three)

Maybe shoving everything into the RootNode (an alternate tree of actual code) isn't such a bad idea...
 - yes it is, at least until we want to be just compiling bytecode
   into a VM I think.

We'll do this sliiightly messy.
 - Scope is its own thing
 - RootNode and Block both own a Scope
 - every Node knows its parentScope
 - every Scope knows its parentScope too!
 - Node implements virtual getScope() { return NULL; } overridden by
   RootNode and Block
 - hasScope should be used by Node to decide who gets what scope

-----

We want to "pretend" add variables into scopes and do lots of really-close-to-evaluation work in analysis steps.  Since I don't want to try and think toooo far ahead in terms of requirements / what a NICE way to do things is, for now let's be pretty brute-force.  Alongside a scope's set of objects will be a "pending" set of objects.  They'll really go into the objects set too, the pending set is just to MARK which ones would need to be rolled-back if we encounter an error.

Similarly, then, an Object (once it exists) will need to track a
pending set of possible modifications.  waaaaaaiiit that gets veeeery
close to "real" side-effecty evaluation, remember, we just want to
*check* that things will work, not *do* them.

And that's why we're not coming up with reqs too early :)  The
pretend-add-var-to-scope is totally reasonable.


-----

AST:
I want it to give as "deep" (semantic) errors as possible, as early as
possible.

We'll have to improve this much later.  For now, we need to do things
in this order, including reordering operators.  That should have
actually been done by the parser, but we'll fix that when we replace
our parser framework someday.

Receive a token:
 - insert it
  - m_current is the most local brace
  - normal nodes becomes children of m_current
  - open braces are set as child, then become the new m_current
 - on closing brace:
  - if irrelevant, move the first child up
  - this first child cannot have children.  If the parser changes to
    allow this, it's a change in the structure of the trees we receive
    from the parser, and it's not clear what it would mean.
  - Now we setup the parent
  - For each child, setup it and then complete it
  - Finally, complete the parent

Setup: parent->children
Complete: children->parent
reorderOperators: parent->children (another pass!)
staticAnalysis: parent->children (another pass!!)

-----

Shell

We currently use a "unified" shell framework:  one lexer, one parser, one evaluator, is shared between the command-line and code.

Instead:  We should eventually change using separate programs for each.  In this model:
shell: master.  Launches subprograms for command-line and code-mode.  Probably, the command-line is built-in to the shell so it's not really a separate program.
command-line processor: accepts lines of text.  Parses out special characters/redirects/etc.  It allows anything within {}'s to be kept as pure text.  It decides which {}'s are expblocks or codeblocks (that's metadata kept alongside the {} chunks).  When it has checked its whole line for errors etc., it passes off the {} chunks to the code processor.  If a { happens with no }, then the code processor is told that it's in charge, and we hand off all the text that we've seen after the {.
code processor: may receive some partial or full text regarding a particular block, and whether it's an expression or a code block.  It may "take charge" of any subsequent user input.  After error-checking, when it evaluates down and has some command-line segments, it can pass these off to the cmd processor to deal with.

-----

Parsing Cmds:
 - let special things like <, >, & get abstracted out (i.e. build partial
   parser support for them)
 - then we can assume that deeper in we don't have them
 - we have a general map of keyword/operator to cmdText
 - we have a wrapper-parser that wraps Keyword or Op in a thing that yields its
   cmdText() as its display instead of bare %s (somehow?)
 - ExpBlocks will still need to be evaluated

ProgramBasic
ProgramArgs
ProgramMore


-----

Interpreter I/O

shell:  stdin, stdout, sterr are to the system/terminal.
shell <-> lexer:
  shell makes 3/4 pipes
  lexer closes 3/4, redirecting its stdin,stdout to them
  shell keeps 3/4 via Lexer Proc; lexer.in/lexer.out route to them
  shell writes to lexer.out and reads from lexer.in
  lexer.err SHOULD still go to shell stderr
  DONE!
shell <-> parser:
  shell makes 5/6 pipes
  parser closes 5/6, redirecting its stdin,stdout to them
  shell keeps 5/6 via Parser Proc; parser.in/parser.out route to them
  shell writes to parser.out and reads from parser.in
  parser.err SHOULD still go to shell stderr
  DONE!
shell <-> evaluator:
  shell makes 7/8 pipes
  eval closes 7/8, redirecting its stdin,stdout to them
  shell keeps 7/8 via Evaluator Proc; eval.in/eval.out route to them
  shell writes to eval.out and reads from eval.in
  eval.err SHOULD still go to shell stderr
  DONE!
evaluator <-> cmd:
  shell ALSO made 9/10 pipes
  shell dupes these to its stdin/stdout
  eval does NOT close 9/10
  eval makes 3/4 pipes
  eval dupes these to its 9/10
  eval keeps 3/4 via Cmd Proc; cmd.in/cmd.out route to them
  cmd closes 3/4, redirecting its stdin,stdout to them

-----

Kill all the "extra channel" nonsense out of Proc.  Proc just sets up stdin/stdout like before, and leaves stderr right alone always.

Evaluator is a child of Proc and implements custom logic.  It may need
an f() component equivalent for the parent (shell) to run right before
the child (eval)'s f().
 -- which means running right before the fork()

BEFORE the eval (child) closes its ORIGINAL stdin/stdout (which are
just the shell's stdin/stdout, going to the terminal), it dupes these
(with a regular dup()) to free file descriptors (which we re-dup to be
3 and 4).  THEN it (eval child) will proceed with the regular logic of
dup'ing shell<->eval communication onto its stdin/stdout, effectively
closing its original stdin/stdout from being real, now they direct to
the shell's channel to us.  Then it closes its file descriptors 9/10
which were its original parent-child channel.

Now the eval has:
  stdin/stdout: communicate to shell's 9/10
  3/4: communicate to TERMINAL stdin/stdout
  9/10: free file descriptors just like any others

Eval has an implementation of a Cmd Proc:
 - Its instinct would be:  pipe() fd's 5/6, cmd's stdin/stdout will communicate to eval's 5/6, eval will do what it wants with them
 - Instead of using pipe() to make up some new fd's, we want the Cmd
   to know to dup its stdin/stdout from some new pipe, but
   specifically from its fds 3/4 (which it should close after).
 - Easy way to get that (MAYBE!): get the parent (eval) to dup its
   magical new 5/6 to its 3/4.  No special logic in the child cmd.
   Huzzaaah!
 - except that has to happen *before* the new Cmd is launched!  So a
   parent_init() needs to exist.
    -- see Proc.h at top of run()

Problem: We need to stop leaking open file descriptors from the shell
to its children (communication channels to *other* children that were
opened first; e.g. right now, the parser can talk directly to the
lexer -- eeeps!!)


=====
  cmd stdin,stdout,stderr
  eval 3/4/5 (which go to shell stdin/stdout/stderr) are provided to
    cmd via Cmd Proc
  eval blocks until cmd is done

Can we get the python logger to not produce parser.log if it didn't write any lines?


AST:
----

{new x; new y}
=> [{(new ID:'x') (new ID:'y')}]

{x}a b c{3+2}d
=> [cmd {(exp ID:'x')} a, b, c {(exp (PLUS INT:'3' INT:'2'))} d]

a b c
=> [cmd a, b, c]

-----
what about

{new x; new y}
  [{(new ID:'x')(new ID:'y')}]

a b c
  [cmd a,b,c]

a {x} b
  [cmd a,{(exp ID:'x')},b]

{x}a b c{3+2}d
  [{(exp ID:'x')}a,b,c{(exp...

-----
or maybe

{new x; new y}
  [{(new x)(new y)}]
a b c
  [ID:'a',ID:'b',ID:'c']

a {x} b
  [ID:'a',{(exp (ID:'x'))},ID:'b']

{x}a b c{3+2}d
  [{(exp (ID:'x'))} ID:'a',ID:'b',ID:'c' {(exp (PLUS INT:'3' INT:'2'))} ID:'d']

